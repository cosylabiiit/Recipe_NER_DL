{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU0A9tXE1PPv"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_trf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sxPx7iHKaee0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from spacy.tokens import DocBin\n",
        "import spacy\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "COWCxM_T84JK"
      },
      "outputs": [],
      "source": [
        "df_train=pd.read_csv('final_train.csv', encoding='utf-8', encoding_errors='ignore')\n",
        "df_train.columns=['sentence','tags']\n",
        "\n",
        "df_test=pd.read_csv('final_test.csv', encoding='utf-8', encoding_errors='ignore')\n",
        "df_test.columns=['sentence','tags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "agjTqbIsVc-i"
      },
      "outputs": [],
      "source": [
        "# function to obtain entity format according to Spacy\n",
        "def get_entity_tuple(df):\n",
        "  list_of_entities = []\n",
        "  for x in range(len(df)):\n",
        "    d = {\"entities\": []}\n",
        "    i, j = 0, 0\n",
        "    idx = -1\n",
        "    \n",
        "    tokens = df[\"tags\"][x].split()\n",
        "    words = df['sentence'][x].split()\n",
        "    if len(words) != len(tokens):\n",
        "      continue\n",
        "\n",
        "    temp = df[\"sentence\"][x] + \" \"\n",
        "    for char in temp:\n",
        "      if char == \" \":\n",
        "        d[\"entities\"].append((i, j, tokens[idx]))\n",
        "        j += 1\n",
        "        i = j\n",
        "        idx += 1\n",
        "      else:\n",
        "        j += 1\n",
        "    list_of_entities.append((df[\"sentence\"][x], d))\n",
        "  \n",
        "  return list_of_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "murGRp3NIK5S"
      },
      "outputs": [],
      "source": [
        "# apply on train and test set\n",
        "train_entities = get_entity_tuple(df_train)\n",
        "test_entities = get_entity_tuple(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ss_Qb_SYbc-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b005e0a6-ce75-4f3d-c8bd-2507df497a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6611/6611 [00:00<00:00, 7190.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping entity\n"
          ]
        }
      ],
      "source": [
        "db = DocBin()\n",
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "for text, annot in tqdm(train_entities): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)\n",
        "    \n",
        "db.to_disk(\"./train.spacy\") # save the docbin object\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Pre6duHDyiIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86307aab-4891-4aa1-b662-42f836b3f4a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2187/2187 [00:00<00:00, 6283.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "db = DocBin()\n",
        "nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "for text, annot in tqdm(test_entities): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)\n",
        "    \n",
        "db.to_disk(\"./test.spacy\") # save the docbin object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJQycZmOlNno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2897001f-083a-4823-d1dd-448a87fb44d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-13 16:39:44.539134: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-13 16:39:44.539464: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-13 16:39:44.539513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-03-13 16:39:59,799] [INFO] Set up nlp object from config\n",
            "[2023-03-13 16:39:59,821] [INFO] Pipeline: ['transformer', 'tagger', 'parser', 'ner']\n",
            "[2023-03-13 16:39:59,821] [INFO] Resuming training for: ['ner', 'parser', 'tagger', 'transformer']\n",
            "[2023-03-13 16:39:59,832] [INFO] Created vocabulary\n",
            "[2023-03-13 16:39:59,834] [INFO] Finished initializing nlp object\n",
            "[2023-03-13 16:39:59,834] [INFO] Initialized pipeline components: []\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'tagger', 'parser', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS TAGGER  LOSS PARSER  LOSS NER  TAG_ACC  DEP_UAS  DEP_LAS  SENTS_F  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  -----------  -----------  --------  -------  -------  -------  -------  ------  ------  ------  ------\n",
            "  0       0        1283.15         0.00         0.00    920.29     0.00     0.00     0.00   100.00    0.00    0.00    0.00    0.00\n",
            "  3     200      137140.72         0.00         0.00  133156.03     0.00     0.00     0.00   100.00   44.56   44.55   44.57    0.15\n",
            "  7     400         963.25         0.00         0.00  83451.28     0.00     0.00     0.00   100.00   57.06   57.43   56.70    0.19\n",
            " 11     600        5842.51         0.00         0.00  47284.15     0.00     0.00     0.00   100.00   93.20   93.18   93.22    0.31\n",
            " 15     800         616.10         0.00         0.00  10507.42     0.00     0.00     0.00   100.00   93.78   93.76   93.81    0.31\n",
            " 19    1000        1559.01         0.00         0.00   6746.92     0.00     0.00     0.00   100.00   94.62   94.60   94.64    0.31\n",
            " 23    1200         657.88         0.00         0.00   4323.31     0.00     0.00     0.00   100.00   95.42   95.39   95.44    0.31\n",
            " 26    1400         365.67         0.00         0.00   2573.56     0.00     0.00     0.00   100.00   95.95   95.93   95.97    0.32\n",
            " 30    1600         446.88         0.00         0.00   1995.15     0.00     0.00     0.00   100.00   95.47   95.45   95.48    0.32\n",
            " 34    1800         203.50         0.00         0.00   1263.17     0.00     0.00     0.00   100.00   95.50   95.49   95.52    0.32\n",
            " 38    2000         154.29         0.00         0.00   1011.96     0.00     0.00     0.00   100.00   95.57   95.55   95.59    0.32\n",
            " 42    2200         131.96         0.00         0.00    956.31     0.00     0.00     0.00   100.00   95.57   95.55   95.59    0.32\n",
            " 46    2400         134.82         0.00         0.00    945.36     0.00     0.00     0.00   100.00   95.57   95.55   95.59    0.32\n",
            " 50    2600         165.34         0.00         0.00    994.36     0.00     0.00     0.00   100.00   95.57   95.55   95.59    0.32\n"
          ]
        }
      ],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./test.spacy --gpu-id 0"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}